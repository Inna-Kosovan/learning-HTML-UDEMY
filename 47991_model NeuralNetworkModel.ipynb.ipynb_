{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"144IJrSAzuIHz-i3Yz4CAk2O8JRCazbD4","timestamp":1698875593097}],"authorship_tag":"ABX9TyMPZOG8AmOGLMurA5ekR33u"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Dk6pEC403QzT"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23895,"status":"ok","timestamp":1698860507084,"user":{"displayName":"Oleh Kondracki","userId":"06214181816493942618"},"user_tz":-60},"id":"_Tsn0N6vHm20","outputId":"b0210f83-914d-4ede-c438-21997a3988d1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":[],"metadata":{"id":"wxwwHnnX3WAj"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ArmsSJ8kz7YI"},"outputs":[],"source":["!pip install tensorflow\n","import tensorflow as tf\n","print(tf.__version__)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ghx-dibHz83o"},"outputs":[],"source":["!pip install pandas scikit-learn tensorflow\n","!pip install matplotlib\n","!pip install tensorflow\n","!pip install scikit-learn\n","!pip install keras\n","!pip install ta\n","!pip install xgboost\n","!pip install joblib\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":914,"status":"ok","timestamp":1698779585493,"user":{"displayName":"Oleh Kondracki","userId":"06214181816493942618"},"user_tz":-60},"id":"_SPfRFdk2uGy","outputId":"682c3d0d-befd-4119-b038-2c08fea5e6de"},"outputs":[{"output_type":"stream","name":"stdout","text":["/job:localhost/replica:0/task:0/device:GPU:0\n","TensorFlow version: 2.14.0\n","GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}],"source":["import tensorflow as tf\n","# ОБОВЯЗКОВО АКТИВУВАТИ\n","# Specify the device for computation\n","with tf.device('/GPU:0'):\n","    # Your TensorFlow operations here\n","    a = tf.constant([1.0, 2.0, 3.0], shape=[3], name='a')\n","    b = tf.constant([1.0, 2.0, 3.0], shape=[3], name='b')\n","    c = tf.add(a, b)\n","\n","# Check the device for the resultant tensor\n","print(c.device)\n","import tensorflow as tf\n","\n","# Check TensorFlow version and GPU availability\n","print(f'TensorFlow version: {tf.__version__}')\n","print(f'GPU Available: {tf.config.list_physical_devices(\"GPU\")}')\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7163,"status":"ok","timestamp":1698779612144,"user":{"displayName":"Oleh Kondracki","userId":"06214181816493942618"},"user_tz":-60},"id":"YwCCPeU693DN","outputId":"01c82e22-c275-4f4b-aec2-c05a77283748"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gputil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: gputil\n","  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=f52992246f0af4bba1f80ccbc62cb2dcf628736f51536eceb448f2eb73a052f2\n","  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n","Successfully built gputil\n","Installing collected packages: gputil\n","Successfully installed gputil-1.4.0\n","GPU ID: 0\n","GPU Name: Tesla T4\n","GPU Memory Free: 14740.0MB\n","GPU Memory Used: 361.0MB\n","GPU Memory Total: 15360.0MB\n","------\n","Num GPUs Available:  1\n"]}],"source":["!pip install gputil\n","import GPUtil\n","\n","# Get the list of available GPU devices\n","gpus = GPUtil.getGPUs()\n","\n","# Print detailed GPU information\n","for gpu in gpus:\n","    print(f\"GPU ID: {gpu.id}\")\n","    print(f\"GPU Name: {gpu.name}\")\n","    # print(f\"GPU Driver Version: {gpu.driverVersion}\")  # Remove or comment out this line\n","    print(f\"GPU Memory Free: {gpu.memoryFree}MB\")\n","    print(f\"GPU Memory Used: {gpu.memoryUsed}MB\")\n","    print(f\"GPU Memory Total: {gpu.memoryTotal}MB\")\n","    print(\"------\")\n","import tensorflow as tf\n","print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":999,"status":"ok","timestamp":1698779619017,"user":{"displayName":"Oleh Kondracki","userId":"06214181816493942618"},"user_tz":-60},"id":"TcfM-OMa2uRH","outputId":"eb11c129-a1e0-402f-eaa3-5e993a0db66b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct 31 19:13:37 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   55C    P0    29W /  70W |    361MiB / 15360MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":588,"status":"ok","timestamp":1698860788043,"user":{"displayName":"Oleh Kondracki","userId":"06214181816493942618"},"user_tz":-60},"id":"kT4CAPPV5Pj3","outputId":"2531b600-0c5a-48ac-8140-cf2b5f30f93d"},"outputs":[{"output_type":"stream","name":"stdout","text":["   EVENT_TIME  TRADE_ID     PRICE  QUANTITY  BUYER_ORDER_ID  SELLER_ORDER_ID  \\\n","0        -1.0 -0.994707  0.715628 -0.999883        0.887518         0.872194   \n","1        -1.0 -0.996208  0.697417 -0.999840        0.887478         0.872303   \n","2        -1.0 -0.996249  0.697417 -0.999883        0.887478         0.872186   \n","3        -1.0 -0.996291  0.696595 -0.999920        0.887478         0.872191   \n","4        -1.0 -0.996333  0.696203 -0.999930        0.887478         0.872140   \n","5        -1.0 -0.996374  0.696007 -0.999883        0.887478         0.872184   \n","6        -1.0 -0.996416  0.695811 -0.999893        0.887478         0.872206   \n","7        -1.0 -0.996458  0.694597 -0.999883        0.887478         0.872180   \n","8        -1.0 -0.996499  0.693383 -0.999893        0.887478         0.872200   \n","9        -1.0 -0.996541  0.693383 -0.999920        0.887478         0.872181   \n","\n","   IS_BUYER_MARKET_MAKER  EMA_short  EMA_long  RSI  ...  Parabolic_SAR  year  \\\n","0                   -1.0  -1.000000  -1.00000 -1.0  ...       0.715628  -1.0   \n","1                   -1.0  -1.000000  -1.00000 -1.0  ...       0.697417  -1.0   \n","2                   -1.0  -1.000000  -1.00000 -1.0  ...       0.715628  -1.0   \n","3                   -1.0  -1.000000  -1.00000 -1.0  ...       0.715276  -1.0   \n","4                   -1.0   0.998917  -1.00000 -1.0  ...       0.714532  -1.0   \n","5                   -1.0   0.998911  -1.00000 -1.0  ...       0.713435  -1.0   \n","6                   -1.0   0.998908  -1.00000 -1.0  ...       0.712025  -1.0   \n","7                   -1.0   0.998904  -1.00000 -1.0  ...       0.710420  -1.0   \n","8                   -1.0   0.998900  -1.00000 -1.0  ...       0.708501  -1.0   \n","9                   -1.0   0.998897   0.99891 -1.0  ...       0.706386  -1.0   \n","\n","   month  day  hour    minute    second  dayofweek  quarter  is_weekend  \n","0   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","1   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","2   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","3   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","4   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","5   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","6   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","7   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","8   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","9   -1.0 -1.0  -1.0  0.254237  0.254237       -1.0     -1.0        -1.0  \n","\n","[10 rows x 23 columns]\n","Total Number of Rows: 47991\n","Total Number of Columns: 23\n","EVENT_TIME               float64\n","TRADE_ID                 float64\n","PRICE                    float64\n","QUANTITY                 float64\n","BUYER_ORDER_ID           float64\n","SELLER_ORDER_ID          float64\n","IS_BUYER_MARKET_MAKER    float64\n","EMA_short                float64\n","EMA_long                 float64\n","RSI                      float64\n","OBV                      float64\n","VWAP                     float64\n","ATR                      float64\n","Parabolic_SAR            float64\n","year                     float64\n","month                    float64\n","day                      float64\n","hour                     float64\n","minute                   float64\n","second                   float64\n","dayofweek                float64\n","quarter                  float64\n","is_weekend               float64\n","dtype: object\n"]}],"source":["import pandas as pd\n","\n","# Load data\n","df = pd.read_csv(\"/content/drive/MyDrive/BINANCE/TRADE_1H/47991_Scaled_v3.csv\")\n","\n","print(df.head(10))\n","# Print the total number of rows and columns\n","num_rows, num_cols = df.shape\n","print(f\"Total Number of Rows: {num_rows}\")\n","print(f\"Total Number of Columns: {num_cols}\")\n","\n","# Display the first few rows of the DataFrame\n","\n","print(df.dtypes)\n","# количество строк и столбцов DataFrame\n","\n","n_rows, n_columns = df.shape\n","print(f\"The DataFrame has {n_rows} rows and {n_columns} columns.\")\n","\n","print(\"Columns in df:\", df.columns)\n","\n","print(\"Shape of X:\", X.shape)\n","print(\"Shape of y:\", y.shape)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"Cbky0z-73V9s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"N9r7myZA3V7C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"pAEts1283V34"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"y1pHO0Hh3V0O"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8BO4wMam71EX"},"outputs":[],"source":["# model NeuralNetworkModel\n","\n","import logging\n","import numpy as np\n","import pandas as pd\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","from sklearn.ensemble import RandomForestRegressor\n","import xgboost as xgb\n","from keras.models import Sequential, load_model\n","from keras.layers import LSTM, Dropout, Dense, BatchNormalization, LeakyReLU\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.regularizers import l2\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from keras_tuner.tuners import RandomSearch\n","import joblib\n","import matplotlib.pyplot as plt\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","\n","logging.basicConfig(level=logging.INFO)\n","def log_execution_time(start_time, message=\"Execution time\"):\n","    \"\"\"Utility function to log the execution time.\"\"\"\n","    end_time = time.time()\n","    elapsed_time = end_time - start_time\n","    minutes = int(elapsed_time // 60)\n","    seconds = int(elapsed_time % 60)\n","    print(f\"{message}: {minutes} minutes and {seconds} seconds\")\n","\n","class NeuralNetworkModel:\n","\n","    def __init__(self, save_directory, df, X_test, y_test, val):\n","        self.save_directory = save_directory\n","        self.df = df\n","        self.X_test = X_test\n","        self.y_test = y_test\n","        self.val = val\n","        self.predictions = {}\n","        self.future_predictions = {}\n","        self.model = self.build_model()\n","\n","    def build_model(self):\n","        model = Sequential()\n","        model.add(LSTM(100, return_sequences=True, input_shape=(self.X_test.shape[1], self.X_test.shape[2])))\n","        model.add(Dropout(0.2))\n","        model.add(BatchNormalization())\n","\n","        model.add(LSTM(100, return_sequences=True))\n","        model.add(Dropout(0.2))\n","        model.add(BatchNormalization())\n","\n","        model.add(LSTM(50))\n","        model.add(Dropout(0.2))\n","        model.add(BatchNormalization())\n","\n","        model.add(Dense(50, activation='relu', kernel_regularizer=l2(0.01)))\n","        model.add(Dropout(0.2))\n","        model.add(BatchNormalization())\n","\n","        model.add(Dense(50))\n","        model.add(LeakyReLU(alpha=0.01))\n","        model.add(Dropout(0.2))\n","        model.add(BatchNormalization())\n","\n","        model.add(Dense(32, activation='relu'))\n","        model.add(Dropout(0.2))\n","        model.add(BatchNormalization())\n","\n","        model.add(Dense(1))\n","\n","        return model\n","\n","    def fit_model(self, X_train, y_train, X_val, y_val, initial_learning_rate, end_learning_rate, epochs, batch_size):\n","        decay_steps = int(epochs * (len(X_train) / batch_size))\n","        lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n","            initial_learning_rate,\n","            decay_steps=decay_steps,\n","            end_learning_rate=end_learning_rate,\n","            power=1.0\n","        )\n","        optimizer = Adam(learning_rate=lr_schedule)\n","        self.model.compile(optimizer=optimizer, loss='mean_squared_error')\n","\n","        early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n","        checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n","\n","        callbacks = [early_stopping, checkpoint]\n","\n","        history = self.model.fit(\n","            X_train, y_train,\n","            validation_data=(X_val, y_val),\n","            epochs=epochs,\n","            batch_size=batch_size,\n","            callbacks=callbacks\n","        )\n","\n","        return history\n","\n","    def evaluate_model(self, y_test_original, y_pred_original):\n","        percentage_accuracy = self.calc_percentage_accuracy(y_test_original, y_pred_original)\n","        rmse = np.sqrt(mean_squared_error(y_test_original, y_pred_original))\n","        print(f'Root Mean Squared Error: {rmse}')\n","        mae = mean_absolute_error(y_test_original, y_pred_original)\n","        print(f'Mean Absolute Error: {mae}')\n","        self.plot_results(y_test_original, y_pred_original, percentage_accuracy)\n","\n","    def calc_percentage_accuracy(self, y_true, y_pred):\n","        return (1 - np.abs((y_pred - y_true) / y_true)) * 100\n","\n","\n","    def save_future_predictions(self, models, timestamps, filename='Future_Predictions.csv'):\n","        full_path = self.save_directory + filename\n","        future_predictions_df = pd.DataFrame({'EVENT_TIME': timestamps})\n","\n","        for model_name, model in models.items():\n","            column_name = f\"{model_name}_Predicted\"\n","            future_predictions_df[column_name] = self.future_predictions[model_name]\n","\n","        # Save future predictions to CSV\n","        future_predictions_df.to_csv(full_path, index=False)\n","\n","        logging.info(f\"Future predictions saved successfully to {full_path}!\")\n","\n","    def save_all_model_predictions(self, models, filename='Predictions.csv'):\n","        full_path = self.save_directory + filename\n","        predictions_df = self.val.copy()\n","        for model_name in models.keys():\n","            column_name = f\"{model_name}_Predicted\"\n","            predictions_df[column_name] = self.predictions[model_name]\n","            if model_name != \"LSTM\":\n","                predictions_df[column_name] = self.inverse_scale_data(predictions_df[column_name].values.reshape(-1, 1)).flatten()\n","\n","        predictions_df.to_csv(full_path, index=False)\n","        logging.info(f\"Predictions saved successfully to {full_path}!\")\n","\n","    def save_model(self, model, filename):\n","        full_path = self.save_directory + filename\n","        if isinstance(model, (RandomForestRegressor, xgb.XGBRegressor)):\n","            joblib.dump(model, full_path)\n","        elif isinstance(model, Sequential):\n","            model.save(full_path)  # Saving the entire model (architecture + weights)\n","        logging.info(f\"Model saved to {filename}!\")\n","\n","    def load_model(self, filename):\n","        full_path = self.save_directory + filename\n","        if filename.endswith('.h5'):\n","            model = load_model(full_path)  # Loading LSTM model\n","        else:\n","            model = joblib.load(full_path)\n","        logging.info(f\"Model loaded from {filename}!\")\n","        return model\n","\n","\n","    def plot_results(self, y_test_original, y_pred_original, percentage_accuracy):\n","        plt.figure(figsize=(15, 5))\n","        plt.subplot(1, 3, 1)\n","        plt.plot(y_test_original, label='True')\n","        plt.plot(y_pred_original, label='Predicted')\n","        plt.title('Prediction vs Real - CLOSE_PRICE')\n","        plt.xlabel('Observation')\n","        plt.ylabel('CLOSE_PRICE')\n","        plt.legend()\n","\n","        plt.subplot(1, 3, 3)\n","        plt.plot(percentage_accuracy, label='Percentage Accuracy')\n","        plt.title('Percentage Accuracy')\n","        plt.xlabel('Observation')\n","        plt.ylabel('Accuracy (%)')\n","        plt.legend()\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def main():\n","        main_start_time = time.time()\n","\n","        save_path = \"/content/drive/MyDrive/BINANCE/TRADE_1H/\"\n","        forecasting = TimeSeriesForecasting(\"/content/drive/MyDrive/BINANCE/TRADE_1H/47991_Scaled_Data_v3.csv\", save_directory=save_path)\n","\n","        # Assuming you have a processor object defined elsewhere in your program\n","        processor = Processor()  # or however you create/obtain this object\n","\n","        # Print memory usage after reading the data\n","        print(\"Memory usage after reading data:\")\n","        processor.print_memory_usage()\n","\n","        # Print memory usage after scaling\n","        print(\"\\nMemory usage after scaling:\")\n","        processor.print_memory_usage()\n","\n","        # Assuming you've defined or will define these methods in the TimeSeriesForecasting class:\n","        forecasting.save_all_model_predictions(models, 'All_Model_Predictions.csv')\n","\n","        # Assuming lstm_model is an attribute of the forecasting object\n","        forecasting.lstm_model.save('neural_network_model.keras')\n","\n","        # Save the dataframe\n","        processor.save_dataframe()\n","\n","        print(processor.df.head())\n","        print(f\"The DataFrame has {processor.df.shape[0]} rows and {processor.df.shape[1]} columns.\")\n","\n","        end_time = time.time()  # End timing\n","        elapsed_time = end_time - main_start_time\n","        minutes = int(elapsed_time // 60)\n","        seconds = int(elapsed_time % 60)\n","\n","        print(f\"Execution time: {minutes} minutes and {seconds} seconds\")\n","\n","    # Assuming you have a log_execution_time function defined elsewhere in your program\n","    # log_execution_time(main_start_time)\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}